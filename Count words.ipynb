{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stop_words import get_stop_words\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# create spark session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark Count words\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "conf = SparkConf().setAppName(\"Python Spark Count words\").setMaster(\"local[2]\")\n",
    "sc = SparkContext(conf=conf)   \n",
    "\n",
    "# https://stackoverflow.com/questions/39882218/py4jjavaerror-an-error-occurred-while-calling-zorg-apache-spark-api-python-pyt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testdata\n",
    "file = sc.wholeTextFiles(\"data/test/*/*.txt\")\n",
    "filesByLang = file.map(lambda x: (x[0].split(\"/\")[-2], x[1])).reduceByKey(lambda v1,v2: v1+ \" \" + v2)\n",
    "wordsByLang = filesByLang.flatMapValues(lambda l: re.findall(\"\\w+\", l))\n",
    "\n",
    "preprocessedWords = wordsByLang.map(lambda x: (x[0], x[1].lower()))\\\n",
    "        .filter(lambda x: (x[1] not in get_stop_words(x[0].lower())))\n",
    "\n",
    "occurences = preprocessedWords.map(lambda w: ((w[0], w[1]), 1))\\\n",
    "        .reduceByKey(lambda v1,v2: v1+v2)\n",
    "occurencesPerLanguage = occurences.sortBy(lambda a: a[1], ascending=False)\\\n",
    "        .filter(lambda x: len(x[0][1]) != 1)\\\n",
    "        .map(lambda x: (x[0][0], (x[0][1], x[1])))\\\n",
    "        .groupByKey()\n",
    "\n",
    "\n",
    "\n",
    "occurencesPerLanguageCollected = occurencesPerLanguage.mapValues(list).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German[('test', 3), ('hallo', 2), ('neuer', 1), ('tolle', 1)]\n",
      "English[('hey', 3), ('test', 1), ('never', 1), ('know', 1), ('say', 1), ('easy', 1)]\n"
     ]
    }
   ],
   "source": [
    "for languages in occurencesPerLanguageCollected:\n",
    "    print(languages[0] + str(languages[1][:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real data\n",
    "file = sc.wholeTextFiles(\"data/texts/*/*.txt\")\n",
    "filesByLang = file.map(lambda x: (x[0].split(\"/\")[-2], x[1])).reduceByKey(lambda v1,v2: v1+ \" \" + v2)\n",
    "wordsByLang = filesByLang.flatMapValues(lambda l: re.findall(\"\\w+\", l))\n",
    "\n",
    "preprocessedWords = wordsByLang.map(lambda x: (x[0], x[1].lower()))\\\n",
    "        .filter(lambda x: (x[1] not in get_stop_words(x[0].lower())))\n",
    "\n",
    "occurences = preprocessedWords.map(lambda w: ((w[0], w[1]), 1))\\\n",
    "        .reduceByKey(lambda v1,v2: v1+v2)\n",
    "occurencesPerLanguage = occurences.sortBy(lambda a: a[1], ascending=False)\\\n",
    "        .filter(lambda x: len(x[0][1]) != 1)\\\n",
    "        .map(lambda x: (x[0][0], (x[0][1], x[1])))\\\n",
    "        .groupByKey()\n",
    "\n",
    "\n",
    "\n",
    "occurencesPerLanguageCollected = occurencesPerLanguage.mapValues(list).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 per language\n",
      "English--> [('said', 18368), ('one', 17930), ('will', 12828), ('upon', 12763), ('now', 11810), ('man', 11763), ('time', 9585), ('well', 9482), ('can', 8902), ('mr', 8743)]\n",
      "\n",
      "German--> [('sagte', 10700), ('ja', 8849), ('schon', 7948), ('mehr', 7026), ('wurde', 6489), ('ganz', 6165), ('sah', 5858), ('rief', 5683), ('wohl', 5647), ('hand', 5610)]\n",
      "\n",
      "Russian--> [('ним', 460), ('глаза', 298), ('друг', 273), ('сердце', 271), ('моей', 255), ('ночь', 241), ('жизни', 234), ('свой', 231), ('знаю', 224), ('горский', 224)]\n",
      "\n",
      "French--> [('plus', 26737), ('dit', 22433), ('bien', 18336), ('homme', 10266), ('dont', 7398), ('rien', 7322), ('puis', 7193), ('monsieur', 7084), ('après', 6781), ('point', 6670)]\n",
      "\n",
      "Italian--> [('disse', 8759), ('egli', 8691), ('poi', 7288), ('quel', 7199), ('quando', 6762), ('due', 6461), ('così', 6239), ('cosa', 5989), ('ora', 5809), ('ella', 5401)]\n",
      "\n",
      "Spanish--> [('si', 5444), ('don', 3073), ('tan', 3026), ('dijo', 2992), ('usted', 2985), ('casa', 2451), ('bien', 2422), ('ser', 2392), ('dos', 2124), ('después', 2092)]\n",
      "\n",
      "Ukrainian--> [('вiн', 1533), ('бо', 1511), ('се', 1469), ('од', 1421), ('от', 1274), ('же', 1224), ('мов', 1205), ('би', 1185), ('те', 1182), ('неначе', 1115)]\n",
      "\n",
      "Dutch--> [('den', 1520), ('gij', 627), ('zoo', 512), ('zijne', 509), ('eene', 488), ('wel', 376), ('marten', 330), ('wij', 318), ('baas', 303), ('zien', 230)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 10 per language\")\n",
    "for languages in occurencesPerLanguageCollected:\n",
    "    print(languages[0] + \"--> \" + str(languages[1][:10]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
